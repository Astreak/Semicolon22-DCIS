# -*- coding: utf-8 -*-
"""histo_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DsLg6q-sh2xeZhEoaUkQKAQU3QpmM4rf
"""

from google.colab import drive
drive.mount('/content/drive')

!python -m pip install histomicstk --find-links https://girder.github.io/large_image_wheels

# Commented out IPython magic to ensure Python compatibility.
import histomicstk as htk

import numpy as np
import scipy as sp

import skimage.io
import skimage.measure
import skimage.color

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
# %matplotlib inline

#Some nice default configuration for plots
plt.rcParams['figure.figsize'] = 10, 10
plt.rcParams['image.cmap'] = 'gray'
titlesize = 24

!ls /content/drive/MyDrive/

import cv2
def get_nuclei_den(image):
  im_input = image
  '''plt.imshow(im_input)
  _ = plt.title('Input Image', fontsize=16)'''

  ref_image_file = ('/content/drive/MyDrive/L1.png')  # L1.png

  im_reference = skimage.io.imread(ref_image_file)[:, :, :3]

  # get mean and stddev of reference image in lab space
  mean_ref, std_ref = htk.preprocessing.color_conversion.lab_mean_std(im_reference)

  # perform reinhard color normalization
  im_nmzd = htk.preprocessing.color_normalization.reinhard(im_input, mean_ref, std_ref)

  # Display results
  '''plt.figure(figsize=(20, 10))

  plt.subplot(1, 2, 1)
  plt.imshow(im_reference)
  _ = plt.title('Reference Image', fontsize=titlesize)

  plt.subplot(1, 2, 2)
  plt.imshow(im_nmzd)
  _ = plt.title('Normalized Input Image', fontsize=titlesize)'''

  stainColorMap = {
      'hematoxylin': [0.65, 0.70, 0.29],
      'eosin':       [0.07, 0.99, 0.11],
      'dab':         [0.27, 0.57, 0.78],
      'null':        [0.0, 0.0, 0.0]
  }

  # specify stains of input image
  stain_1 = 'hematoxylin'   # nuclei stain
  stain_2 = 'eosin'         # cytoplasm stain
  stain_3 = 'null'          # set to null of input contains only two stains

  # create stain matrix
  W = np.array([stainColorMap[stain_1],
                stainColorMap[stain_2],
                stainColorMap[stain_3]]).T

  # perform standard color deconvolution
  im_stains = htk.preprocessing.color_deconvolution.color_deconvolution(im_nmzd, W).Stains

  # Display results
  '''plt.figure(figsize=(20, 10))

  plt.subplot(1, 2, 1)
  plt.imshow(im_stains[:, :, 0])
  plt.title(stain_1, fontsize=titlesize)

  plt.subplot(1, 2, 2)
  plt.imshow(im_stains[:, :, 1])
  _ = plt.title(stain_2, fontsize=titlesize)'''
  im_nuclei_stain = im_stains[:, :, 0]

  # segment foreground
  foreground_threshold = 60

  im_fgnd_mask = sp.ndimage.morphology.binary_fill_holes(
      im_nuclei_stain < foreground_threshold)

  # run adaptive multi-scale LoG filter
  min_radius = 10
  max_radius = 15

  im_log_max, im_sigma_max = htk.filters.shape.cdog(
      im_nuclei_stain, im_fgnd_mask,
      sigma_min=min_radius * np.sqrt(2),
      sigma_max=max_radius * np.sqrt(2)
  )

  # detect and segment nuclei using local maximum clustering
  local_max_search_radius = 10

  im_nuclei_seg_mask, seeds, maxima = htk.segmentation.nuclear.max_clustering(
      im_log_max, im_fgnd_mask, local_max_search_radius)

  # filter out small objects
  min_nucleus_area = 80

  im_nuclei_seg_mask = htk.segmentation.label.area_open(
      im_nuclei_seg_mask, min_nucleus_area).astype(np.int64)

  # compute nuclei properties
  objProps = skimage.measure.regionprops(im_nuclei_seg_mask)
  return len(objProps)

  # # Display results
  # plt.figure(figsize=(20, 10))

  # plt.subplot(1, 2, 1)
  # plt.imshow(skimage.color.label2rgb(im_nuclei_seg_mask, im_input, bg_label=0), origin='lower')
  # plt.title('Nuclei segmentation mask overlay', fontsize=titlesize)

  # plt.subplot(1, 2, 2)
  # plt.imshow( im_input )
  # plt.xlim([0, im_input.shape[1]])
  # plt.ylim([0, im_input.shape[0]])
  # plt.title('Nuclei bounding boxes', fontsize=titlesize)

  # for i in range(len(objProps)):

  #     c = [objProps[i].centroid[1], objProps[i].centroid[0], 0]
  #     width = objProps[i].bbox[3] - objProps[i].bbox[1] + 1
  #     height = objProps[i].bbox[2] - objProps[i].bbox[0] + 1

  #     cur_bbox = {
  #         "type":        "rectangle",
  #         "center":      c,
  #         "width":       width,
  #         "height":      height,
  #     }

  #     plt.plot(c[0], c[1], 'g+')
  #     mrect = mpatches.Rectangle([c[0] - 0.5 * width, c[1] - 0.5 * height] ,
  #                               width, height, fill=False, ec='g', linewidth=2)
  #     plt.gca().add_patch(mrect)

  # plt.show()

!pip3 install opencv-python-headless==4.1.2.30

get_nuclei_den('/content/drive/MyDrive/0_N/BRACS_283_N_3.png')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import *
import os
import zipfile
import shutil
from tqdm.auto import tqdm
import cv2
import tqdm
from imageio import *
from torchvision import *
import torchvision.transforms as transforms
plt.rcParams['figure.figsize']=(12,15)
dev='cpu'
if torch.cuda.is_available():
  dev='cuda'
dev=torch.device(dev)
plt.style.use('fivethirtyeight')
for i in os.listdir('/content/5_DCIS'):
  ok=i.split('.');
  if ok[1]!='png' or len(ok)>2:
    print(i)
    shutil.rmtree(os.path.join('/content/5_DCIS',i))

List_paths=[]
for i,j in zip(os.listdir('/content/5_DCIS'),os.listdir('/content/drive/MyDrive/0_N')):
  List_paths.append(os.path.join('/content/5_DCIS',i));
  List_paths.append(os.path.join('/content/drive/MyDrive/0_N',j))

# op=1e9
# for i in os.listdir('/content/5_DCIS'):
#   ok=imread(os.path.join('/content/5_DCIS',i))
#   op=min(op,ok.shape[0])
#   op=min(op,ok.shape[1])
#   del ok
# op

def center_cropping_image(read_img):
  mid_pointy=read_img.shape[0]//2;
  mid_pointx=read_img.shape[1]//2;
  xshape=read_img.shape[1]
  yshape=read_img.shape[0]
  return read_img[max(0,mid_pointy-512):min(yshape,mid_pointy+512),max(0,mid_pointx-512):min(xshape,mid_pointx+512),:]
def windowing_image(read_img,lab):
  assert read_img.shape[0]==1024 and read_img.shape[1]==1024
  L=np.zeros((4,4,1))
  row=0
  col=0
  for i in range(0,512,128):
    for j in range(0,512,128):
      L[row,col,0]=get_nuclei_den(read_img[i:i+512,j:j+512,:])
      if col+1==4:
        col=0;
        row+=1;
      else:
        col+=1;
  return L
def create_heat(path):
    read_img=imread(path)
    xshape=read_img.shape[1]
    yshape=read_img.shape[0]
    if read_img.shape[0]<1024 or read_img.shape[1]<1024:
      tmp_op=np.zeros((max(read_img.shape[0],1024),max(read_img.shape[1],1024),3))
      tmp_op.fill(255)
      tmp_op[:read_img.shape[0],:read_img.shape[1],:]=read_img
      read_img=tmp_op
    lab=0
    if 'DCIS' in path:
      lab=1;
    read_img=center_cropping_image(read_img)
    L=windowing_image(read_img,lab)
    return L;
#create_heat('/content/drive/MyDrive/0_N/BRACS_1231_N_61.png')

class CreatePatches(Dataset):
  def __init__(self,path,transforms=None):
    self.path=path
    self.transforms=transforms
  def __len__(self):
    return self.path.__len__()
  def __getitem__(self,indx):
    img=self.path[indx]
    inp=create_heat(img)
    inp=torch.tensor(inp.astype(np.float32)).reshape(1,4,4)
    label=torch.tensor([0.],dtype=torch.float32)
    if 'DCIS' in img:
      label=torch.tensor([1.],dtype=torch.float32)
    return inp,label
dataset=CreatePatches(List_paths,transforms=transforms.Compose([transforms.Normalize(mean=(0.5),std=(0.5))]))
Train=DataLoader(dataset,shuffle=True,batch_size=2,drop_last=True)

for x,y in Train:
  print(x.shape)
  break

class SmallConvNet(nn.Module):
  def __init__(self,shape=4):
    super(SmallConvNet,self).__init__()
    self.shape=shape
    self.l1=nn.Conv2d(1,32,kernel_size=(3,3),padding='same')
    self.r=nn.ReLU(inplace=True)
    self.l2=nn.Conv2d(32,64,kernel_size=(3,3),padding='same')
    self.l3=nn.MaxPool2d(kernel_size=2)
    self.l4=nn.Conv2d(64,16,kernel_size=3,padding='same')
    self.l5=nn.Flatten()
    self.linear=nn.Sequential(
          nn.Linear(2*2*16,64),
          nn.ReLU(inplace=True),
          nn.Linear(64,16),
          nn.ReLU(inplace=True),
          nn.Linear(16,1)
      )
  def forward(self,x):
    x=self.r(self.l1(x))
    x=self.r(self.l2(x))
    x=self.l3(x)
    x=self.r(self.l4(x))
    x=self.l5(x)
    return self.linear(x)
model=SmallConvNet()
model.to(dev)

optimizer=torch.optim.Adam(model.parameters())
loss_fn=nn.BCEWithLogitsLoss()
for e in range(1):
  model.train()
  L=0
  S=0;
  pbar=tqdm.tqdm(Train,desc='Training');
  for x,y in pbar:
    x,y=x.to(dev),y.to(dev)
    pred=model(x)
    loss=loss_fn(pred,y)
    loss.backward()
    optimizer.step()
    L+=loss.item()
    S+=1;
  print(L/S)

